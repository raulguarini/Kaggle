{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Elastic Net Implementation for Talking Data\n",
    "## Alessandro Rivello and Raul Guarini - \"Econometristas''\n",
    "Vers√£o com undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "path = \"../input/\"\n",
    "\n",
    "import gc, time\n",
    "dtypes = {\n",
    "    'ip'            : 'uint32',\n",
    "    'app'           : 'uint16',\n",
    "    'device'        : 'uint16',\n",
    "    'os'            : 'uint16',\n",
    "    'channel'       : 'uint16',\n",
    "    'is_attributed' : 'uint8',\n",
    "    'click_id'      : 'uint32'\n",
    "}\n",
    "\n",
    "def handleClickHour(df):\n",
    "    df['click_hour']= (pd.to_datetime(df['click_time']).dt.round('H')).dt.hour\n",
    "    df['click_hour'] = df['click_hour'].astype('uint8')\n",
    "    df = df.drop(['click_time'], axis=1)   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load df_train_30m with 140.21 seconds\n"
     ]
    }
   ],
   "source": [
    "# Importing data\n",
    "train_columns = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']\n",
    "\n",
    "# Load training df (partly)\n",
    "start_time = time.time()\n",
    "start = 133333333\n",
    "size = 33333333\n",
    "df_train_30m = pd.read_csv(path + 'train.csv', dtype=dtypes, skiprows=range(1,33333333), nrows=133333333, usecols=train_columns)\n",
    "# df_train_30m = pd.read_csv(path + 'train.csv', dtype=dtypes, usecols=train_columns)\n",
    "print('Load df_train_30m with {} seconds'.format(round(time.time() - start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load df_test with 21.816 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load testing df\n",
    "start_time = time.time()\n",
    "df_test = pd.read_csv(path + 'test.csv', dtype=dtypes)\n",
    "print('Load df_test with {} seconds'.format(round(time.time() - start_time, 3)))\n",
    "\n",
    "train_record_index = df_train_30m.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClickTime data correctly handled.\n"
     ]
    }
   ],
   "source": [
    "# Handle click hour \n",
    "df_train_30m = handleClickHour(df_train_30m)\n",
    "df_test = handleClickHour(df_test)\n",
    "gc.collect();\n",
    "print('ClickTime data correctly handled.')\n",
    "\n",
    "# df for submit\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit['click_id'] = df_test['click_id']\n",
    "# Extracting learning data\n",
    "Learning_Y = df_train_30m['is_attributed']\n",
    "print('Training target correctly extracted.')\n",
    "\n",
    "#drop zone\n",
    "df_test = df_test.drop(['click_id'], axis=1)\n",
    "df_train_30m = df_train_30m.drop(['is_attributed'], axis=1)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.concat([df_train_30m, df_test])\n",
    "del df_train_30m, df_test\n",
    "gc.collect();\n",
    "print('Data was correctly concatenated')\n",
    "\n",
    "# Count ip for both train and test df \n",
    "start_time = time.time()\n",
    "df_ip_count = df_merge['ip'].value_counts().reset_index(name = 'ip_count')\n",
    "df_ip_count.columns = ['ip', 'ip_count']\n",
    "print('Loaded df_ip_count with {} seconds'.format(round(time.time() - start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting to merge with main dataset...')\n",
    "df_merge = df_merge.merge(df_ip_count, on='ip', how='left', sort=False)\n",
    "df_merge['ip_count'] = df_merge['ip_count'].astype('uint16')\n",
    "print('Merging operation completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't need the ip information anymore\n",
    "df_merge = df_merge.drop(['ip'], axis=1)\n",
    "del df_ip_count\n",
    "gc.collect();\n",
    "\n",
    "# Tracing back what is training data and what is test data\n",
    "df_train = df_merge[:train_record_index]\n",
    "df_test = df_merge[train_record_index:]\n",
    "\n",
    "del df_merge\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the RandomUnderSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(return_indices=True)\n",
    "start_time = time.time()\n",
    "train_resampled, Y_resampled, idx_resampled = rus.fit_sample(X = df_train, y = Learning_Y)\n",
    "print(\"Elapsed time until undersampling was complete: {:.2f} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the undersampled data in DataFrames\n",
    "X_resampled = pd.DataFrame(train_resampled, columns=df_train.columns)\n",
    "Y_resampled = pd.DataFrame(Y_resampled, columns=['is_attributed'])\n",
    "\n",
    "del train_resampled, idx_resampled\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a cross-validation structure for simple evaluation\n",
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_cv, Y_train, Y_cv = model_selection.train_test_split(X_resampled, Y_resampled, train_size = 0.7)\n",
    "gc.collect();\n",
    "print('Data splitting into training and cross validation is done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a way to evaluate the model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def clf_eval(y_true, y_pred):\n",
    "    print('Classification Report')\n",
    "    \n",
    "    print('ROC Score: {}'.format(roc_auc_score(y_true, y_pred)))\n",
    "    \n",
    "    return roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting Elastic Net Implementation\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "print('Starting to fit the model to the training dataset... The machine is learning...')\n",
    "\n",
    "start_time = time.time()\n",
    "mae_dina = SGDClassifier(loss = 'log', penalty = 'elasticnet', alpha = 50, l1_ratio = 0.001, n_jobs = 5,\n",
    "                        verbose = 0, )\n",
    "trained_model = mae_dina.fit(X_train, Y_train)\n",
    "\n",
    "print('Machine has learned. Elapsed time: {:.2f} seconds'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting\n",
    "print('Starting cross-validation prediction phase...')\n",
    "start_time = time.time()\n",
    "predictions = trained_model.predict_proba(X_cv)[:,1]\n",
    "print('Prediction done. Elapsed time: {:.2f} seconds'.format(time.time() - start_time))\n",
    "\n",
    "# Evaluating the model\n",
    "clf_eval(Y_cv, predictions);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acabamos por nem submeter o csv gerado desta forma pois o desempenho foi bem abaixo do esperado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
