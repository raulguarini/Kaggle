{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest com mais features e, talvez, algum undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "\n",
    "import gc, time\n",
    "\n",
    "dtypes = {\n",
    "    'ip'            : 'uint32',\n",
    "    'app'           : 'uint16',\n",
    "    'device'        : 'uint16',\n",
    "    'os'            : 'uint16',\n",
    "    'channel'       : 'uint16',\n",
    "    'is_attributed' : 'uint8',\n",
    "    'click_id'      : 'uint32'\n",
    "}\n",
    "\n",
    "# Correcting path to data inside EMAp's server\n",
    "path = '/dados/Dados/Kaggle/'\n",
    "\n",
    "def handleClickHour_raul(df):\n",
    "    df['click_hour']= pd.to_datetime(df['click_time']).dt.hour.astype('uint8')\n",
    "    df['click_minute'] = pd.to_datetime(df['click_time']).dt.minute.astype('uint8')\n",
    "    df['click_second'] = pd.to_datetime(df['click_time']).dt.second.astype('uint8')\n",
    "    df = df.drop(['click_time'], axis=1)   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df_train_30m with 137.732 seconds\n"
     ]
    }
   ],
   "source": [
    "# Importing data\n",
    "train_columns = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']\n",
    "\n",
    "# Load training df (partly) - this takes 2-4 minutes\n",
    "start_time = time.time()\n",
    "df_train_30m = pd.read_csv(path + 'train.csv', dtype=dtypes, skiprows=range(1,133333333), \n",
    "                           nrows=35000000, usecols=train_columns)\n",
    "print('Loaded df_train_30m with {} seconds'.format(round(time.time() - start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df_test with 22.245 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load testing df\n",
    "start_time = time.time()\n",
    "df_test = pd.read_csv(path + 'test.csv', dtype=dtypes)\n",
    "print('Loaded df_test with {} seconds'.format(round(time.time() - start_time, 3)))\n",
    "\n",
    "train_record_index = df_train_30m.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClickTime data correctly handled.\n"
     ]
    }
   ],
   "source": [
    "# Handle click hour \n",
    "df_train_30m = handleClickHour_raul(df_train_30m)\n",
    "df_test = handleClickHour_raul(df_test)\n",
    "gc.collect();\n",
    "print('ClickTime data correctly handled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df for submit\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit['click_id'] = df_test['click_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target correctly extracted.\n"
     ]
    }
   ],
   "source": [
    "#Extracting learning data\n",
    "Learning_Y = df_train_30m['is_attributed']\n",
    "print('Training target correctly extracted.')\n",
    "\n",
    "#drop zone\n",
    "df_test = df_test.drop(['click_id'], axis=1)\n",
    "df_train_30m = df_train_30m.drop(['is_attributed'], axis=1)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was correctly concatenated\n"
     ]
    }
   ],
   "source": [
    "# The df_merge just places training data and testing data together so we can create features together\n",
    "df_merge = pd.concat([df_train_30m, df_test])\n",
    "\n",
    "# We have already extracted the target column and merged everything, so we can delete these dataframes and trace them\n",
    "# back as we need!!\n",
    "del df_train_30m, df_test\n",
    "gc.collect();\n",
    "print('Data was correctly concatenated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df_ip_count with 6.311 seconds\n"
     ]
    }
   ],
   "source": [
    "# Count ip for both train and test df \n",
    "start_time = time.time()\n",
    "df_ip_count = df_merge['ip'].value_counts().reset_index(name = 'ip_count')\n",
    "df_ip_count.columns = ['ip', 'ip_count']\n",
    "print('Loaded df_ip_count with {} seconds'.format(round(time.time() - start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to merge with main dataset...\n",
      "Merging operation completed.\n"
     ]
    }
   ],
   "source": [
    "print('Starting to merge with main dataset...')\n",
    "df_merge = df_merge.merge(df_ip_count, on='ip', how='left', sort=False)\n",
    "df_merge['ip_count'] = df_merge['ip_count'].astype('uint16')\n",
    "print('Merging operation completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df_os_count with 1.29 seconds\n",
      "Starting to merge with main dataset...\n",
      "Merging operation completed.\n"
     ]
    }
   ],
   "source": [
    "# Doing the same for OS\n",
    "start_time = time.time()\n",
    "df_os_count = df_merge['os'].value_counts().reset_index(name = 'os_count')\n",
    "df_os_count.columns = ['os', 'os_count']\n",
    "print('Loaded df_os_count with {:.2f} seconds'.format(time.time() - start_time))\n",
    "print('Starting to merge with main dataset...')\n",
    "df_merge = df_merge.merge(df_os_count, on='os', how='left', sort=False).astype('uint8')\n",
    "print('Merging operation completed.')\n",
    "del df_os_count\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df_app_count with 0.70 seconds\n",
      "Starting to merge with main dataset...\n",
      "Merging operation completed.\n"
     ]
    }
   ],
   "source": [
    "# Doing the same for APP\n",
    "start_time = time.time()\n",
    "df_app_count = df_merge['app'].value_counts().reset_index(name = 'app_count')\n",
    "df_app_count.columns = ['app', 'app_count']\n",
    "print('Loaded df_app_count with {:.2f} seconds'.format(time.time() - start_time))\n",
    "print('Starting to merge with main dataset...')\n",
    "df_merge = df_merge.merge(df_app_count, on='app', how='left', sort=False).astype('uint8')\n",
    "print('Merging operation completed.')\n",
    "del df_app_count\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df_dev_count with 1.25 seconds\n",
      "Starting to merge with main dataset...\n",
      "Merging operation completed.\n"
     ]
    }
   ],
   "source": [
    "# Doing the same for DEVICE\n",
    "start_time = time.time()\n",
    "df_dev_count = df_merge['device'].value_counts().reset_index(name = 'dev_count')\n",
    "df_dev_count.columns = ['device', 'dev_count']\n",
    "print('Loaded df_dev_count with {:.2f} seconds'.format(time.time() - start_time))\n",
    "print('Starting to merge with main dataset...')\n",
    "df_merge = df_merge.merge(df_dev_count, on='device', how='left', sort=False).astype('uint8')\n",
    "print('Merging operation completed.')\n",
    "del df_dev_count\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_hour</th>\n",
       "      <th>click_minute</th>\n",
       "      <th>click_second</th>\n",
       "      <th>ip_count</th>\n",
       "      <th>os_count</th>\n",
       "      <th>app_count</th>\n",
       "      <th>dev_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>59</td>\n",
       "      <td>144</td>\n",
       "      <td>205</td>\n",
       "      <td>219</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>59</td>\n",
       "      <td>251</td>\n",
       "      <td>211</td>\n",
       "      <td>195</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>59</td>\n",
       "      <td>215</td>\n",
       "      <td>9</td>\n",
       "      <td>221</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>59</td>\n",
       "      <td>194</td>\n",
       "      <td>205</td>\n",
       "      <td>157</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>59</td>\n",
       "      <td>61</td>\n",
       "      <td>125</td>\n",
       "      <td>219</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ip  app  device  os  channel  click_hour  click_minute  click_second  \\\n",
       "0  190    9       1  13      134           0            25            59   \n",
       "1  168   21       1  22      128           0            25            59   \n",
       "2  172   11       1  19      137           0            25            59   \n",
       "3  189   12       1  13       19           0            25            59   \n",
       "4   52    9       1  26      210           0            25            59   \n",
       "\n",
       "   ip_count  os_count  app_count  dev_count  \n",
       "0       144       205        219         24  \n",
       "1       251       211        195         24  \n",
       "2       215         9        221         24  \n",
       "3       194       205        157         24  \n",
       "4        61       125        219         24  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing everything for some Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a way to evaluate the model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def clf_eval(y_true, y_pred):\n",
    "    print('Classification Report')\n",
    "   # print('F-1 Score: {}'.format(f1_score(y_true, y_pred)))\n",
    "    print('ROC Score: {}'.format(roc_auc_score(y_true, y_pred)))\n",
    "    return roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting into training and cross validation is done.\n"
     ]
    }
   ],
   "source": [
    "# Tracing back\n",
    "df_train = df_merge[:train_record_index].copy()\n",
    "df_test = df_merge[train_record_index:].copy()\n",
    "\n",
    "# Creating a cross-validation set\n",
    "from sklearn import model_selection\n",
    "X_train, X_cv, Y_train, Y_cv = model_selection.train_test_split(df_train, Learning_Y, train_size = 0.7)\n",
    "gc.collect();\n",
    "print('Data splitting into training and cross validation is done.')\n",
    "del df_merge\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive implementation of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to fit Random Forest Model... The machine is learning...\n",
      "building tree 1 of 13building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13building tree 11 of 13\n",
      "\n",
      "building tree 12 of 13building tree 13 of 13\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=13)]: Done   2 out of  13 | elapsed:  6.9min remaining: 38.0min\n",
      "[Parallel(n_jobs=13)]: Done   9 out of  13 | elapsed:  7.3min remaining:  3.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The machine has learned.\n",
      "RandomForest has fitted df_train_30m with 445.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=13)]: Done  13 out of  13 | elapsed:  7.4min finished\n"
     ]
    }
   ],
   "source": [
    "# Start of Random Forest Implementation with no fancy stuff\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print('Starting to fit Random Forest Model... The machine is learning...')\n",
    "start_time = time.time()\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=13, max_depth=13, random_state=13, verbose=2, n_jobs = 13)\n",
    "rf.fit(X_train, Y_train)\n",
    "print('The machine has learned.')\n",
    "print('RandomForest has fitted df_train_30m with {:.2f} seconds'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cross-validation prediction phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=13)]: Done   2 out of  13 | elapsed:    3.4s remaining:   18.8s\n",
      "[Parallel(n_jobs=13)]: Done   9 out of  13 | elapsed:    3.9s remaining:    1.7s\n",
      "[Parallel(n_jobs=13)]: Done  13 out of  13 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction done. Elapsed time: 4.98 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Starting cross-validation prediction phase...')\n",
    "start_time = time.time()\n",
    "predictions = rf.predict_proba(X_cv)[:,1]\n",
    "print('Prediction done. Elapsed time: {:.2f} seconds'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "ROC Score: 0.9483143345829378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9483143345829378"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "clf_eval(Y_cv, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UnderSampling to see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the RandomUnderSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(return_indices=True)\n",
    "start_time = time.time()\n",
    "\n",
    "train_resampled, Y_resampled, idx_resampled = rus.fit_sample(X = X_train, y = Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the undersampled data in DataFrames\n",
    "X_resampled = pd.DataFrame(train_resampled, columns=df_train.columns)\n",
    "Y_resampled = pd.DataFrame(Y_resampled, columns=['is_attributed'])\n",
    "\n",
    "del train_resampled, idx_resampled\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "[Parallel(n_jobs=18)]: Done   6 out of  13 | elapsed:    0.5s remaining:    0.6s\n",
      "[Parallel(n_jobs=18)]: Done  13 out of  13 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The machine has learned.\n",
      "RandomForest has fitted X_train with 0.6496496200561523 seconds\n",
      "Starting cross-validation prediction phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=13)]: Done   2 out of  13 | elapsed:    3.5s remaining:   19.3s\n",
      "[Parallel(n_jobs=13)]: Done  13 out of  13 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction done. Elapsed time: 5.129887819290161 seconds\n",
      "Classification Report\n",
      "ROC Score: 0.957046765680315\n"
     ]
    }
   ],
   "source": [
    "# Running Random Forest again\n",
    "start_time = time.time()\n",
    "rf_resampled = RandomForestClassifier(n_estimators=13, \n",
    "                                      max_depth=13, \n",
    "                                      random_state=13, \n",
    "                                      verbose=1, \n",
    "                                      n_jobs = 18)\n",
    "\n",
    "\n",
    "rf_resampled.fit(X_resampled, Y_resampled)\n",
    "print('The machine has learned.')\n",
    "print('RandomForest has fitted X_train with {} seconds'.format(time.time() - start_time))\n",
    "\n",
    "print('Starting cross-validation prediction phase...')\n",
    "start_time = time.time()\n",
    "predictions = rf_resampled.predict_proba(X_cv)[:,1]\n",
    "print('Prediction done. Elapsed time: {} seconds'.format(time.time() - start_time))\n",
    "\n",
    "# Evaluating the model\n",
    "clf_eval(Y_cv, predictions);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
